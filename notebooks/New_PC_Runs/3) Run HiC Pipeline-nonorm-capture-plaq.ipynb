{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from core.utils import Tibanna\n",
    "from dcicutils import ff_utils\n",
    "from core.utils import run_workflow\n",
    "from datetime import datetime\n",
    "from core.wfr import *\n",
    "\n",
    "env = 'data'\n",
    "tibanna = Tibanna(env=env)\n",
    "\n",
    "ff = ff_utils.fdn_connection(key={\"default\" : tibanna.ff_keys})\n",
    "exclude_miseq = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 total number of sets\n",
      "1 sets completed\n",
      "\n",
      "1 4DNESQMO66LZ PLAC-seq\n",
      "MboI human\n",
      "4DNEXLV8HIAA part1 complete\n",
      "4DNEXLV8HIAA part2 complete\n",
      "4DNEXMN2HP68 part1 complete\n",
      "4DNEXMN2HP68 part2 complete\n",
      "4DNESQMO66LZ part3 complete\n",
      "\n",
      "2 4DNESTZUCQH5 capture Hi-C\n",
      "MboI human\n",
      "4DNEXQXUGDXG part1 complete\n",
      "4DNEXQXUGDXG part2 complete\n",
      "4DNESTZUCQH5 part3 complete\n",
      "\n",
      "3 4DNES8TLFCMQ capture Hi-C\n",
      "MboI human\n",
      "4DNEX2VTRKTP part1 complete\n",
      "4DNEX2VTRKTP part2 complete\n",
      "4DNES8TLFCMQ part3 complete\n",
      "\n",
      "4 4DNESQ9YYPQZ capture Hi-C\n",
      "MboI human\n",
      "4DNEXFETO9VX part1 complete\n",
      "4DNEXFETO9VX part2 complete\n",
      "4DNEXCQ2ZNXO part1 complete\n",
      "4DNEXCQ2ZNXO part2 complete\n",
      "4DNESQ9YYPQZ part3 complete\n",
      "\n",
      "5 4DNES917ZVA6 capture Hi-C\n",
      "MboI human\n",
      "4DNEX83M7A57 part1 complete\n",
      "4DNEX83M7A57 part2 complete\n",
      "4DNES917ZVA6 part3 complete\n",
      "\n",
      "6 4DNESWPMRBIZ capture Hi-C\n",
      "MboI human\n",
      "4DNEXYUI9JCI part1 complete\n",
      "4DNEXYUI9JCI part2 complete\n",
      "4DNEXPSSVEUO part1 complete\n",
      "4DNEXPSSVEUO part2 complete\n",
      "4DNESWPMRBIZ part3 complete\n",
      "\n",
      "7 4DNESNI4PPYX capture Hi-C\n",
      "MboI human\n",
      "4DNEX7JISNEA part1 complete\n",
      "4DNEX7JISNEA part2 complete\n",
      "4DNESNI4PPYX part3 complete\n",
      "\n",
      "8 4DNESAVVP47G capture Hi-C\n",
      "MboI human\n",
      "4DNEX4XIH9I8 part1 complete\n",
      "4DNEX4XIH9I8 part2 complete\n",
      "4DNESAVVP47G part3 complete\n",
      "\n",
      "9 4DNES2ZDGCY5 capture Hi-C\n",
      "MboI human\n",
      "4DNEX1GEXL4R part1 complete\n",
      "4DNEX1GEXL4R part2 complete\n",
      "4DNES2ZDGCY5 part3 complete\n",
      "\n",
      "10 4DNESA2R77LP capture Hi-C\n",
      "MboI human\n",
      "4DNEX47BWKZQ part1 complete\n",
      "4DNEX47BWKZQ part2 complete\n",
      "4DNEXX33SRFJ part1 complete\n",
      "4DNEXX33SRFJ part2 complete\n",
      "4DNESA2R77LP part3 complete\n",
      "\n",
      "11 4DNESVGV5YDR capture Hi-C\n",
      "MboI human\n",
      "4DNEXF6CEY13 part1 complete\n",
      "4DNEXF6CEY13 part2 complete\n",
      "4DNEXAKJPY9Y part1 complete\n",
      "4DNEXAKJPY9Y part2 complete\n",
      "4DNESVGV5YDR part3 complete\n",
      "\n",
      "12 4DNES4A1BNPI capture Hi-C\n",
      "MboI human\n",
      "4DNEXMNAPSO2 part1 complete\n",
      "4DNEXMNAPSO2 part2 complete\n",
      "4DNEX914EZ8N part1 complete\n",
      "4DNEX914EZ8N part2 complete\n",
      "4DNES4A1BNPI part3 complete\n",
      "\n",
      "13 4DNESR1UBP9L capture Hi-C\n",
      "MboI human\n",
      "4DNEXAJWZB18 part1 complete\n",
      "4DNEXAJWZB18 part2 complete\n",
      "4DNEXR9SQK76 part1 complete\n",
      "4DNEXR9SQK76 part2 complete\n",
      "4DNEX9WXSU5B part1 complete\n",
      "4DNEX9WXSU5B part2 complete\n",
      "4DNESR1UBP9L part3 complete\n",
      "\n",
      "14 4DNESNOJ28YT capture Hi-C\n",
      "MboI human\n",
      "4DNEXRZJ37CB part1 complete\n",
      "4DNEXRZJ37CB part2 complete\n",
      "4DNEXURO3NJZ part1 complete\n",
      "4DNEXURO3NJZ part2 complete\n",
      "4DNESNOJ28YT part3 complete\n",
      "\n",
      "15 4DNESMSJXT8O capture Hi-C\n",
      "MboI human\n",
      "4DNEXVKIGPTN part1 complete\n",
      "4DNEXVKIGPTN part2 complete\n",
      "4DNEX8KBUJ6S part1 complete\n",
      "4DNEX8KBUJ6S part2 complete\n",
      "4DNESMSJXT8O part3 complete\n",
      "\n",
      "16 4DNESNCK7FEW capture Hi-C\n",
      "MboI human\n",
      "4DNEXJ9DMCWX part1 complete\n",
      "4DNEXJ9DMCWX part2 complete\n",
      "4DNEX4IKF8FY part1 complete\n",
      "4DNEX4IKF8FY part2 complete\n",
      "4DNESNCK7FEW part3 complete\n",
      "\n",
      "17 4DNESLBTEN66 capture Hi-C\n",
      "MboI human\n",
      "4DNEX88KQH75 part1 complete\n",
      "4DNEX88KQH75 part2 complete\n",
      "4DNESLBTEN66 part3 complete\n",
      "\n",
      "18 4DNES5YI4ZCE capture Hi-C\n",
      "MboI human\n",
      "4DNEXLFZA8EQ part1 complete\n",
      "4DNEXLFZA8EQ part2 complete\n",
      "4DNES5YI4ZCE part3 complete\n",
      "\n",
      "19 4DNESZ4F7V39 capture Hi-C\n",
      "MboI human\n",
      "4DNEXCVXZY97 part1 complete\n",
      "4DNEXCVXZY97 part2 complete\n",
      "4DNESZ4F7V39 part3 complete\n",
      "\n",
      "20 4DNESRF2JLP3 capture Hi-C\n",
      "MboI human\n",
      "4DNEX9GCPXZN part1 complete\n",
      "4DNEX9GCPXZN part2 complete\n",
      "4DNEXHG5WSK5 part1 complete\n",
      "4DNEXHG5WSK5 part2 complete\n",
      "4DNESRF2JLP3 part3 complete\n",
      "\n",
      "21 4DNESWQ4K74H capture Hi-C\n",
      "MboI human\n",
      "4DNEXWQOA5OG part1 complete\n",
      "4DNEXWQOA5OG part2 complete\n",
      "4DNEXCGG8BKP part1 complete\n",
      "4DNEXCGG8BKP part2 complete\n",
      "4DNEXT66BJKO part1 complete\n",
      "4DNEXT66BJKO part2 complete\n",
      "4DNEXMCKZQUA part1 complete\n",
      "4DNEXMCKZQUA part2 complete\n",
      "4DNESWQ4K74H part3 complete\n",
      "\n",
      "22 4DNESWZZWT68 capture Hi-C\n",
      "MboI human\n",
      "4DNEXGG59BQC part1 complete\n",
      "4DNEXGG59BQC part2 complete\n",
      "4DNEXR4F5WJJ part1 complete\n",
      "4DNEXR4F5WJJ part2 complete\n",
      "4DNEXJIB98HQ part1 complete\n",
      "4DNEXJIB98HQ part2 complete\n",
      "4DNEX4SJDB52 part1 complete\n",
      "4DNEX4SJDB52 part2 complete\n",
      "part3 still running\n",
      "\n",
      "23 4DNESAYH7WXY capture Hi-C\n",
      "MboI human\n",
      "4DNEX7FI4QSK part1 complete\n",
      "4DNEX7FI4QSK part2 complete\n",
      "4DNESAYH7WXY part3 complete\n",
      "\n",
      "24 4DNESWFRUPLR capture Hi-C\n",
      "MboI human\n",
      "4DNEXY744GG9 part1 complete\n",
      "4DNEXY744GG9 part2 complete\n",
      "4DNEXK179IOV part1 complete\n",
      "4DNEXK179IOV part2 complete\n",
      "4DNEX8KPXKZE part1 complete\n",
      "4DNEX8KPXKZE part2 complete\n",
      "4DNEXU2KZRN9 part1 complete\n",
      "4DNEXU2KZRN9 part2 complete\n",
      "part3 still running\n",
      "\n",
      "25 4DNESYP3AUZS capture Hi-C\n",
      "MboI human\n",
      "4DNEXBAAXHZW part1 complete\n",
      "4DNEXBAAXHZW part2 complete\n",
      "4DNESYP3AUZS part3 complete\n",
      "\n",
      "26 4DNESJWXORCI capture Hi-C\n",
      "MboI human\n",
      "4DNEXDG1ROVP part1 complete\n",
      "4DNEXDG1ROVP part2 complete\n",
      "4DNEX8SFWCYB part1 complete\n",
      "4DNEX8SFWCYB part2 complete\n",
      "4DNEXQ9SRQJN part1 complete\n",
      "4DNEXQ9SRQJN part2 complete\n",
      "4DNEXLWSXULR part1 complete\n",
      "4DNEXLWSXULR part2 complete\n",
      "part3 still running\n",
      "\n",
      "27 4DNES3CUDIXW capture Hi-C\n",
      "MboI human\n",
      "4DNEX1BOSCUW part1 complete\n",
      "4DNEX1BOSCUW part2 complete\n",
      "4DNEX5PPVGJN part1 complete\n",
      "4DNEX5PPVGJN part2 complete\n",
      "4DNEXU67SGF3 part1 complete\n",
      "4DNEXU67SGF3 part2 complete\n",
      "4DNEXPUK1J27 part1 complete\n",
      "4DNEXPUK1J27 part2 complete\n",
      "part3 still running\n",
      "\n",
      "28 4DNESG4XBHWB capture Hi-C\n",
      "MboI human\n",
      "4DNEXV22N38P part1 complete\n",
      "4DNEXV22N38P part2 complete\n",
      "4DNEXFHWUX8H part1 complete\n",
      "4DNEXFHWUX8H part2 complete\n",
      "4DNEXTJBAHTN part1 complete\n",
      "4DNEXTJBAHTN part2 complete\n",
      "4DNEX23TSUEX part1 complete\n",
      "4DNEX23TSUEX part2 complete\n",
      "part3 still running\n",
      "\n",
      "29 4DNESEYZC9D9 capture Hi-C\n",
      "MboI human\n",
      "4DNEX8VI8Q77 part1 complete\n",
      "4DNEX8VI8Q77 part2 complete\n",
      "4DNEX5H8FKJV part1 complete\n",
      "4DNEX5H8FKJV part2 complete\n",
      "4DNEXRIDF1WQ part1 complete\n",
      "4DNEXRIDF1WQ part2 complete\n",
      "4DNEXAF8PXDJ part1 complete\n",
      "4DNEXAF8PXDJ part2 complete\n",
      "4DNEX4RF5AW7 part1 complete\n",
      "4DNEX4RF5AW7 part2 complete\n",
      "4DNEXTIGW52V part1 complete\n",
      "4DNEXTIGW52V part2 complete\n",
      "4DNEX9UG6UO9 part1 complete\n",
      "4DNEX9UG6UO9 part2 complete\n",
      "part3 still running\n",
      "23\n",
      "[u'4DNESQMO66LZ', u'4DNESTZUCQH5', u'4DNES8TLFCMQ', u'4DNESQ9YYPQZ', u'4DNES917ZVA6', u'4DNESWPMRBIZ', u'4DNESNI4PPYX', u'4DNESAVVP47G', u'4DNES2ZDGCY5', u'4DNESA2R77LP', u'4DNESVGV5YDR', u'4DNES4A1BNPI', u'4DNESR1UBP9L', u'4DNESNOJ28YT', u'4DNESMSJXT8O', u'4DNESNCK7FEW', u'4DNESLBTEN66', u'4DNES5YI4ZCE', u'4DNESZ4F7V39', u'4DNESRF2JLP3', u'4DNESWQ4K74H', u'4DNESAYH7WXY', u'4DNESYP3AUZS']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# for a given experiment set and some parameters like instrument\n",
    "# print set of files and their partA hic workflow status\n",
    "# if there are one that are running report the number of running cases\n",
    "# if there are file pairs that don't have a corresponding part A, report them separately\n",
    "\n",
    "out_n = \"This is an output file of the Hi-C processing pipeline\"\n",
    "int_n = \"This is an intermediate file in the HiC processing pipeline\"\n",
    "\n",
    "def step_settings(seq, my_organism):\n",
    "    genome = \"\"\n",
    "    mapper = {'human':'GRCh38','mouse':'GRCm38'}\n",
    "    genome = mapper.get(my_organism)\n",
    "    \n",
    "    wf_dict =[{\n",
    "        'wf_name': 'bwa-mem',\n",
    "        'wf_uuid': '3feedadc-50f9-4bb4-919b-09a8b731d0cc',\n",
    "        'parameters': {\"nThreads\": 16},\n",
    "        'custom_pf_fields': {\n",
    "            'out_bam': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'intermediate file',\n",
    "                'description': int_n}\n",
    "        }},\n",
    "        {\n",
    "        'wf_name': 'hi-c-processing-bam',\n",
    "        'wf_uuid': '023bfb3e-9a8b-42b9-a9d4-216079526f68',\n",
    "        'parameters': {\"nthreads_merge\": 16, \"nthreads_parse_sort\": 16},\n",
    "        'custom_pf_fields': {\n",
    "            'annotated_bam': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'alignment',\n",
    "                'description': out_n},\n",
    "            'filtered_pairs': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact list-replicate',\n",
    "                'description': out_n}\n",
    "        }},\n",
    "        {\n",
    "        'wf_name': 'hi-c-processing-pairs-nonorm',\n",
    "        'wf_uuid': 'bd6e25ea-f368-4758-a821-d30e0b5a4100',\n",
    "        'parameters': {\"nthreads\": 1, \"maxmem\": \"32g\"},\n",
    "        'custom_pf_fields': {\n",
    "#             'cooler_normvector': {\n",
    "#                 'genome_assembly': genome,\n",
    "#                 'file_type': 'juicebox norm vector',\n",
    "#                 'description': out_n},\n",
    "            'hic': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact matrix',\n",
    "                'description': out_n},\n",
    "            'mcool': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact matrix',\n",
    "                'description': out_n},\n",
    "            'merged_pairs': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact list-combined',\n",
    "                'description': out_n}\n",
    "        }}]\n",
    "    \n",
    "    return wf_dict[seq]\n",
    "\n",
    "\n",
    "# url for hic exps\n",
    "exp_types = ['capture%20Hi-C', 'PLAC-seq']\n",
    "set_url = '/search/?'+ \\\n",
    "            '&'.join(['experiments_in_set.experiment_type='+i for i in exp_types])+ \\\n",
    "            '&type=ExperimentSetReplicate&limit=all' + \\\n",
    "            '&status=released&status=released%20to%20project'\n",
    "run_sets = ff_utils.search_metadata(set_url , ff_env=env)\n",
    "\n",
    "add_pc = False\n",
    "add_rel = False\n",
    "add_wfr = False\n",
    "\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "\n",
    "all_sets = len(run_sets)\n",
    "print(str(all_sets)+' total number of sets')\n",
    "run_sets = [i for i in run_sets if \"HiC_Pipeline_0.2.5\"  not in i.get('completed_processes', [])]\n",
    "print(str(all_sets-len(run_sets))+ ' sets completed')\n",
    "\n",
    "for a_set in run_sets: \n",
    "    counter += 1\n",
    "    print\n",
    "\n",
    "    fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size = find_pairs(a_set, exclude_miseq, env, tibanna)\n",
    "\n",
    "    if not bwa_ref or not chrsize_ref:\n",
    "        print counter, a_set['accession'], organism, enzyme, 'skipping set with not chrsize/bwa index'\n",
    "        continue\n",
    "    \n",
    "    if not enz_ref:\n",
    "        print counter, a_set['accession'], 'skipping not ready NZ', organism, enzyme\n",
    "        continue\n",
    "    \n",
    "#     if f_size < 0.00001:\n",
    "#         print counter, a_set['accession'], 'skipping small file size', str(f_size) \n",
    "#         continue\n",
    "        \n",
    "    print counter, a_set['accession'], a_set['experiments_in_set'][0]['experiment_type']\n",
    "    print enzyme, organism\n",
    "    part3 = 'done'\n",
    "    list_release = []\n",
    "    set_pairs = []        \n",
    "    # cycle through the experiments\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq pairs')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        part2 = 'done'\n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            bam1 = get_wfr_out(pair[0], 'bwa-mem 0.2.5', 'bam', env)\n",
    "            bam2 = get_wfr_out(pair[1], 'bwa-mem 0.2.5', 'bam', env)\n",
    "            # if run is not successful\n",
    "            if bam1.startswith('no') or not bam1 or bam1 != bam2:\n",
    "                part1 = 'not ready'\n",
    "                if add_wfr:\n",
    "                    if not bwa_index:\n",
    "                        print 'not yet usable', organism\n",
    "                        continue\n",
    "                    inp_f = {'fastq1':pair[0], 'fastq2':pair[1], 'bwa_index':bwa_ref}\n",
    "                    name_tag = pair[0].split('/')[2]+'_'+pair[1].split('/')[2]\n",
    "                    run_missing_wfr(step_settings(0, organism), inp_f, name_tag, env, tibanna)\n",
    "            elif bam1 == 'running':\n",
    "                part1 = 'still running'\n",
    "                print('part1 still running')\n",
    "            # if successful\n",
    "            else:\n",
    "                exp_bams.append(bam1)\n",
    "                list_release.append(bam1)\n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print exp, 'has missing Part1 runs'\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print exp, 'part1 complete'\n",
    "        #check if part 2 is run already, it not start the run\n",
    "        exp_com_bam = []\n",
    "        exp_pairs = []\n",
    "        for bam in exp_bams:\n",
    "            com_bam = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', 'bam', env)\n",
    "            pairs = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', 'pairs', env)\n",
    "            # try to run if missing\n",
    "            if pairs.startswith('no') or not pairs:\n",
    "                part2 = 'not ready'\n",
    "                part3 = 'not ready'\n",
    "                \n",
    "            elif pairs == 'running':\n",
    "                part2 = 'still running'\n",
    "                part3 = 'not ready'\n",
    "                \n",
    "            else:\n",
    "                exp_com_bam.append(com_bam)\n",
    "                exp_pairs.append(pairs)\n",
    "                \n",
    "        # if still running, skip to next experiment\n",
    "        if part2 == 'still running':\n",
    "            print('part2 still running')\n",
    "            continue\n",
    "        \n",
    "        # make sure all bams went through the same wfr and produces same file\n",
    "        if part2 != 'done' or len(list(set(exp_com_bam))) != 1 or len(list(set(exp_pairs))) !=1:\n",
    "            print exp, 'Part2 did not complete'\n",
    "            part3 = 'not ready' \n",
    "        \n",
    "            if add_wfr:\n",
    "                if not chrsize_ref:\n",
    "                    print 'not yet usable', organism\n",
    "                    continue\n",
    "                # make sure no duplicates\n",
    "                inp_f = {'input_bams':exp_bams, 'chromsize':chrsize_ref}           \n",
    "                run_missing_wfr(step_settings(1, organism), inp_f, exp, env, tibanna)   \n",
    "            continue\n",
    "            \n",
    "        # add bam and pairs to exp proc file\n",
    "        list_release.extend([exp_com_bam[0],exp_pairs[0]])\n",
    "        if add_pc:\n",
    "            add_processed_files(exp, [exp_com_bam[0],exp_pairs[0]], env)\n",
    "        \n",
    "        print exp, 'part2 complete'\n",
    "        set_pairs.append(exp_pairs[0])\n",
    "    \n",
    "    if part3 != 'done':\n",
    "        print 'Part3 not ready'\n",
    "        continue\n",
    "    \n",
    "    if not set_pairs:\n",
    "        print 'no pairs can be produced from this set'\n",
    "        continue\n",
    "        \n",
    "    merged_pairs = []\n",
    "    for set_pair in set_pairs:\n",
    "        merged_pair = get_wfr_out(set_pair, 'hi-c-processing-pairs-nonorm 0.2.5', 'pairs', env)\n",
    "        hic = get_wfr_out(set_pair, 'hi-c-processing-pairs-nonorm 0.2.5', 'hic', env)\n",
    "        mcool = get_wfr_out(set_pair, 'hi-c-processing-pairs-nonorm 0.2.5', 'mcool', env)\n",
    "        #normvec = get_wfr_out(set_pair, 'hi-c-processing-pairs-nonorm 0.2.5', 'normvector_juicerformat', env)\n",
    "        if merged_pair.startswith('no') or not merged_pair:\n",
    "            part3 = 'not ready'\n",
    "            break\n",
    "        elif merged_pair == 'running':\n",
    "            part3 = 'still running'\n",
    "            break\n",
    "        else:\n",
    "            merged_pairs.append(merged_pair)\n",
    "    \n",
    "    \n",
    "    # if part3 is still running report it, and skip the rest of the script\n",
    "    if part3 == 'still running':\n",
    "        print 'part3', part3\n",
    "        continue        \n",
    "                \n",
    "    if part3 != 'done' or len(list(set(merged_pairs))) != 1:\n",
    "        print a_set['accession'], 'is missing Part3'\n",
    "        \n",
    "        # if it is not run, and add_wfr is true, go for it, then skip the rest of the script\n",
    "        if add_wfr:\n",
    "            if not chrsize_ref:\n",
    "                print 'not yet usable', organism\n",
    "                continue\n",
    "\n",
    "            if not enz_ref:\n",
    "                print 'restriction enzyme not ready for', organism, enzyme\n",
    "                continue\n",
    "            inp_f = {'input_pairs':set_pairs, 'chromsizes':chrsize_ref, 'restriction_file': enz_ref} \n",
    "            run_missing_wfr(step_settings(2, organism), inp_f, a_set['accession'], env, tibanna)\n",
    "        continue\n",
    "    #####\n",
    "    #add competed flag to experiment\n",
    "    if add_pc and add_rel:\n",
    "        ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.5\"]}, obj_id=a_set['accession'] , ff_env=env)\n",
    "    \n",
    "    # add processed files to set\n",
    "    list_release.extend([merged_pair, hic, mcool])\n",
    "    if add_pc:\n",
    "        add_processed_files(a_set['accession'], [merged_pair, hic, mcool], env)\n",
    "    \n",
    "    #release files and wfrs\n",
    "    if add_rel:\n",
    "        release_files(a_set['accession'], list(set(list_release)), env)\n",
    "    \n",
    "    completed += 1\n",
    "    completed_acc.append(a_set['accession'])\n",
    "    print a_set['accession'], 'part3 complete'\n",
    "\n",
    "    \n",
    "print completed\n",
    "print completed_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
