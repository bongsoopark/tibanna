{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from core.utils import Tibanna\n",
    "from dcicutils import ff_utils\n",
    "from core.utils import run_workflow\n",
    "from datetime import datetime\n",
    "from core.wfr import *\n",
    "\n",
    "env = 'data'\n",
    "tibanna = Tibanna(env=env)\n",
    "\n",
    "ff = ff_utils.fdn_connection(key={\"default\" : tibanna.ff_keys})\n",
    "exclude_miseq = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 total number of sets\n",
      "1 sets completed\n",
      "\n",
      "1 4DNESQBZ6L8Z\n",
      "None human\n",
      "4DNEX37BWPZT part1 complete\n",
      "4DNEX37BWPZT part2 complete\n",
      "4DNEXCZUE2D9 part1 complete\n",
      "4DNEXCZUE2D9 part2 complete\n",
      "4DNEX9Q3KJG8 part1 complete\n",
      "4DNEX9Q3KJG8 part2 complete\n",
      "4DNEXWL452NZ part1 complete\n",
      "4DNEXWL452NZ part2 complete\n",
      "4DNESQBZ6L8Z part3 complete\n",
      "\n",
      "2 4DNES5BDII8F\n",
      "None human\n",
      "4DNEX15HMJS9 part1 complete\n",
      "4DNEX15HMJS9 part2 complete\n",
      "4DNEXE2EER1V part1 complete\n",
      "4DNEXE2EER1V part2 complete\n",
      "4DNEXAHVP5SD part1 complete\n",
      "4DNEXAHVP5SD part2 complete\n",
      "4DNEXXRV8DHE part1 complete\n",
      "4DNEXXRV8DHE part2 complete\n",
      "4DNES5BDII8F part3 complete\n",
      "\n",
      "3 4DNESR9S8R38\n",
      "None human\n",
      "4DNEX7EOOU1F part1 complete\n",
      "4DNEX7EOOU1F part2 complete\n",
      "4DNEXZ2ES9TT part1 complete\n",
      "4DNEXZ2ES9TT part2 complete\n",
      "4DNESR9S8R38 part3 complete\n",
      "\n",
      "4 4DNESO1IVQSC\n",
      "None human\n",
      "4DNEX8Z7LXRO part1 complete\n",
      "4DNEX8Z7LXRO part2 complete\n",
      "4DNEXHMB4QAD part1 complete\n",
      "4DNEXHMB4QAD part2 complete\n",
      "4DNEXB3O53RF part1 complete\n",
      "4DNEXB3O53RF part2 complete\n",
      "4DNESO1IVQSC part3 complete\n",
      "\n",
      "5 4DNESNPHX8LY\n",
      "None human\n",
      "4DNEX6B5D93H part1 complete\n",
      "4DNEX6B5D93H part2 complete\n",
      "4DNEXM8U6XE3 part1 complete\n",
      "4DNEXM8U6XE3 part2 complete\n",
      "4DNEXKGUSP2D part1 complete\n",
      "4DNEXKGUSP2D part2 complete\n",
      "4DNESNPHX8LY part3 complete\n",
      "5\n",
      "[u'4DNESQBZ6L8Z', u'4DNES5BDII8F', u'4DNESR9S8R38', u'4DNESO1IVQSC', u'4DNESNPHX8LY']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# for a given experiment set and some parameters like instrument\n",
    "# print set of files and their partA hic workflow status\n",
    "# if there are one that are running report the number of running cases\n",
    "# if there are file pairs that don't have a corresponding part A, report them separately\n",
    "\n",
    "out_n = \"This is an output file of the Hi-C processing pipeline\"\n",
    "int_n = \"This is an intermediate file in the HiC processing pipeline\"\n",
    "\n",
    "def step_settings(seq, my_organism):\n",
    "    genome = \"\"\n",
    "    mapper = {'human':'GRCh38','mouse':'GRCm38'}\n",
    "    genome = mapper.get(my_organism)\n",
    "    \n",
    "    wf_dict =[{\n",
    "        'wf_name': 'bwa-mem',\n",
    "        'wf_uuid': '3feedadc-50f9-4bb4-919b-09a8b731d0cc',\n",
    "        'parameters': {\"nThreads\": 16},\n",
    "        'custom_pf_fields': {\n",
    "            'out_bam': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'intermediate file',\n",
    "                'description': int_n}\n",
    "        }},\n",
    "        {\n",
    "        'wf_name': 'hi-c-processing-bam',\n",
    "        'wf_uuid': '023bfb3e-9a8b-42b9-a9d4-216079526f68',\n",
    "        'parameters': {\"nthreads_merge\": 16, \"nthreads_parse_sort\": 16},\n",
    "        'custom_pf_fields': {\n",
    "            'annotated_bam': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'alignment',\n",
    "                'description': out_n},\n",
    "            'filtered_pairs': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact list-replicate',\n",
    "                'description': out_n}\n",
    "        }},\n",
    "        {\n",
    "        'wf_name': 'hi-c-processing-pairs-nore-nonorm',\n",
    "        'wf_uuid': '05b62bba-7bfa-46cc-8d8e-3d37f4feb8bd',\n",
    "        'parameters': {\"nthreads\": 1, \"maxmem\": \"32g\"},\n",
    "        'custom_pf_fields': {\n",
    "#             'cooler_normvector': {\n",
    "#                 'genome_assembly': genome,\n",
    "#                 'file_type': 'juicebox norm vector',\n",
    "#                 'description': out_n},\n",
    "            'hic': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact matrix',\n",
    "                'description': out_n},\n",
    "            'mcool': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact matrix',\n",
    "                'description': out_n},\n",
    "            'merged_pairs': {\n",
    "                'genome_assembly': genome,\n",
    "                'file_type': 'contact list-combined',\n",
    "                'description': out_n}\n",
    "        }}]\n",
    "    \n",
    "    return wf_dict[seq]\n",
    "\n",
    "\n",
    "# url for chiapet tracloop\n",
    "exp_types = ['CHIA-pet', 'TrAC-loop']\n",
    "set_url = '/search/?'+ \\\n",
    "            '&'.join(['experiments_in_set.experiment_type='+i for i in exp_types])+ \\\n",
    "            '&type=ExperimentSetReplicate&limit=all'\n",
    "\n",
    "run_sets = ff_utils.search_metadata(set_url , ff_env=env)\n",
    "\n",
    "add_pc = False\n",
    "add_rel = False\n",
    "add_wfr = False\n",
    "\n",
    "counter = 0\n",
    "completed = 0\n",
    "completed_acc = []\n",
    "\n",
    "all_sets = len(run_sets)\n",
    "print(str(all_sets)+' total number of sets')\n",
    "run_sets = [i for i in run_sets if \"HiC_Pipeline_0.2.5\"  not in i.get('completed_processes', [])]\n",
    "print(str(all_sets-len(run_sets))+ ' sets completed')\n",
    "\n",
    "for a_set in run_sets: \n",
    "    counter += 1\n",
    "    print\n",
    "    fastqpairs, organism, enzyme, bwa_ref, chrsize_ref, enz_ref, f_size = find_pairs(a_set, exclude_miseq, env, tibanna)\n",
    "\n",
    "    if not bwa_ref or not chrsize_ref:\n",
    "        print counter, a_set['accession'], organism, enzyme, 'skipping set with not chrsize/bwa index'\n",
    "        continue     \n",
    "        \n",
    "    print counter, a_set['accession']\n",
    "    print enzyme, organism\n",
    "    part3 = 'done'\n",
    "    list_release = []\n",
    "    set_pairs = []        \n",
    "    # cycle through the experiments\n",
    "    for exp in fastqpairs.keys():\n",
    "        if not fastqpairs.get(exp):\n",
    "            print(exp, 'does not have any fastq pairs')\n",
    "            continue\n",
    "        # Check Part 1 and See if all are okay\n",
    "        exp_bams = []\n",
    "        part1 = 'done'\n",
    "        part2 = 'done'\n",
    "        for pair in fastqpairs[exp]:\n",
    "            #############\n",
    "            bam1 = get_wfr_out(pair[0], 'bwa-mem 0.2.5', 'bam', env)\n",
    "            bam2 = get_wfr_out(pair[1], 'bwa-mem 0.2.5', 'bam', env)\n",
    "            # if run is not successful\n",
    "            if bam1.startswith('no') or not bam1 or bam1 != bam2:\n",
    "                part1 = 'not ready'\n",
    "                if add_wfr:\n",
    "                    if not bwa_index:\n",
    "                        print 'not yet usable', organism\n",
    "                        continue\n",
    "                    inp_f = {'fastq1':pair[0], 'fastq2':pair[1], 'bwa_index':bwa_ref}\n",
    "                    name_tag = pair[0].split('/')[2]+'_'+pair[1].split('/')[2]\n",
    "                    run_missing_wfr(step_settings(0, organism), inp_f, name_tag, ff, env, tibanna)\n",
    "            elif bam1 == 'running':\n",
    "                part1 = 'still running'\n",
    "                print('part1 still running')\n",
    "            # if successful\n",
    "            else:\n",
    "                exp_bams.append(bam1)\n",
    "                list_release.append(bam1)\n",
    "        # stop progress to part2 \n",
    "        if part1 is not 'done':\n",
    "            print exp, 'has missing Part1 runs'\n",
    "            part2 = 'not ready'\n",
    "            part3 = 'not ready'\n",
    "            continue\n",
    "        print exp, 'part1 complete'\n",
    "        #check if part 2 is run already, it not start the run\n",
    "        exp_com_bam = []\n",
    "        exp_pairs = []\n",
    "        for bam in exp_bams:\n",
    "            com_bam = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', 'bam', env)\n",
    "            pairs = get_wfr_out(bam, 'hi-c-processing-bam 0.2.5', 'pairs', env)\n",
    "            # try to run if missing\n",
    "            if pairs.startswith('no') or not pairs:\n",
    "                part2 = 'not ready'\n",
    "                part3 = 'not ready'\n",
    "                \n",
    "            elif pairs == 'running':\n",
    "                part2 = 'still running'\n",
    "                part3 = 'not ready'\n",
    "                \n",
    "            else:\n",
    "                exp_com_bam.append(com_bam)\n",
    "                exp_pairs.append(pairs)\n",
    "                \n",
    "        # if still running, skip to next experiment\n",
    "        if part2 == 'still running':\n",
    "            print('part2 still running')\n",
    "            continue\n",
    "        \n",
    "        # make sure all bams went through the same wfr and produces same file\n",
    "        if part2 != 'done' or len(list(set(exp_com_bam))) != 1 or len(list(set(exp_pairs))) !=1:\n",
    "            print exp, 'Part2 did not complete'\n",
    "            part3 = 'not ready' \n",
    "        \n",
    "            if add_wfr:\n",
    "                if not chrsize_ref:\n",
    "                    print 'not yet usable', organism\n",
    "                    continue\n",
    "                # make sure no duplicates\n",
    "                inp_f = {'input_bams':exp_bams, 'chromsize':chrsize_ref}           \n",
    "                run_missing_wfr(step_settings(1, organism), inp_f, exp, env, tibanna)   \n",
    "            continue\n",
    "            \n",
    "        # add bam and pairs to exp proc file\n",
    "        list_release.extend([exp_com_bam[0],exp_pairs[0]])\n",
    "        if add_pc:\n",
    "            add_processed_files(exp, [exp_com_bam[0],exp_pairs[0]], env)\n",
    "        \n",
    "        print exp, 'part2 complete'\n",
    "        set_pairs.append(exp_pairs[0])\n",
    "    \n",
    "    if part3 != 'done':\n",
    "        print 'Part3 not ready'\n",
    "        continue\n",
    "    \n",
    "    if not set_pairs:\n",
    "        print 'no pairs can be produced from this set'\n",
    "        continue\n",
    "        \n",
    "    merged_pairs = []\n",
    "    for set_pair in set_pairs:\n",
    "        merged_pair = get_wfr_out(set_pair, 'hi-c-processing-pairs-nore-nonorm 0.2.5', 'pairs', env)\n",
    "        hic = get_wfr_out(set_pair, 'hi-c-processing-pairs-nore-nonorm 0.2.5', 'hic', env)\n",
    "        mcool = get_wfr_out(set_pair, 'hi-c-processing-pairs-nore-nonorm 0.2.5', 'mcool', env)\n",
    "        #normvec = get_wfr_out(set_pair, 'hi-c-processing-pairs-nore-nonorm 0.2.5', 'normvector_juicerformat', env)\n",
    "        if merged_pair.startswith('no') or not merged_pair:\n",
    "            part3 = 'not ready'\n",
    "            break\n",
    "        elif merged_pair == 'running':\n",
    "            part3 = 'still running'\n",
    "            break\n",
    "        else:\n",
    "            merged_pairs.append(merged_pair)\n",
    "    \n",
    "    \n",
    "    # if part3 is still running report it, and skip the rest of the script\n",
    "    if part3 == 'still running':\n",
    "        print 'part3', part3\n",
    "        continue        \n",
    "                \n",
    "    if part3 != 'done' or len(list(set(merged_pairs))) != 1:\n",
    "        print a_set['accession'], 'is missing Part3'\n",
    "        \n",
    "        # if it is not run, and add_wfr is true, go for it, then skip the rest of the script\n",
    "        if add_wfr:\n",
    "            if not chrsize_ref:\n",
    "                print 'not yet usable', organism\n",
    "                continue\n",
    "\n",
    "            inp_f = {'input_pairs':set_pairs, 'chromsizes':chrsize_ref} \n",
    "            run_missing_wfr(step_settings(2, organism), inp_f, a_set['accession']+\"_5\", env, tibanna)\n",
    "        continue\n",
    "    #####\n",
    "    #add competed flag to experiment\n",
    "    if add_pc and add_rel:\n",
    "        ff_utils.patch_metadata({\"completed_processes\":[\"HiC_Pipeline_0.2.5\"]}, obj_id=a_set['accession'], ff_env=env)\n",
    "    \n",
    "    # add processed files to set\n",
    "    list_release.extend([merged_pair, hic, mcool])\n",
    "    if add_pc:\n",
    "        add_processed_files(a_set['accession'], [merged_pair, hic, mcool], env)\n",
    "    \n",
    "    #release files and wfrs\n",
    "    if add_rel:\n",
    "        release_files(a_set['accession'], list(set(list_release)), env)\n",
    "    \n",
    "    completed += 1\n",
    "    completed_acc.append(a_set['accession'])\n",
    "    print a_set['accession'], 'part3 complete'\n",
    "\n",
    "    \n",
    "print completed\n",
    "print completed_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
