{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "428\n",
      "100 + 0\n",
      "200 + 0\n",
      "300 + 0\n",
      "400 + 0\n",
      "object 46e82a90-49e5-4c33-afab-9ec90d65cca1/4DNFIO67AFHV.fastq.gz not found on bucket elasticbeanstalk-fourfront-webprod-files\n",
      "An error occurred (404) when calling the HeadObject operation: Not Found\n",
      "/files-fastq/4DNFIO67AFHV/ uploaded\n",
      "1 files missing from s3\n",
      "0 files had patch problems\n",
      "0 deleted files skipped\n",
      "427 uploading files skipped\n",
      "0 total files patched\n"
     ]
    }
   ],
   "source": [
    "from core.utils import Tibanna\n",
    "from dcicutils import ff_utils\n",
    "\n",
    "\n",
    "# for a given experiment set and some parameters like instrument\n",
    "# print set of files and their partA hic workflow status\n",
    "# if there are one that are running report the number of running cases\n",
    "# if there are file pairs that don't have a corresponding part A, report them separately\n",
    "\n",
    "env = 'data'\n",
    "tibanna = Tibanna(env=env)\n",
    "ff = ff_utils.fdn_connection(key={\"default\" : tibanna.ff_keys})\n",
    "\n",
    "file_not_found = 0\n",
    "deleted = 0\n",
    "uploading = 0\n",
    "success = 0\n",
    "patch_problem = 0\n",
    "\n",
    "\n",
    "files_resp = ff_utils.search_metadata('/search/?type=File&file_size=No+value&limit=all', ff_env = env)\n",
    "\n",
    "print len(files_resp)\n",
    "\n",
    "no_size = 0\n",
    "counter = 0\n",
    "for a_file in files_resp:\n",
    "    if a_file['status'] == 'deleted':\n",
    "        deleted += 1\n",
    "        continue\n",
    "    counter += 1\n",
    "    if counter % 100 == 0:\n",
    "        print counter,\"+\" ,deleted\n",
    "    if a_file['status'] in ['uploading', 'to be uploaded by workflow']:\n",
    "        uploading += 1\n",
    "        continue\n",
    "    # check if there is  no filesize\n",
    "    if not a_file.get('file_size'):\n",
    "        # decide on the bucket\n",
    "        if 'FileProcessed' in a_file['@type']:\n",
    "            bucket = tibanna.s3.outfile_bucket\n",
    "        else:\n",
    "            bucket = tibanna.s3.raw_file_bucket\n",
    "            \n",
    "        # check if file is in s3\n",
    "        head_info = tibanna.s3.does_key_exist(a_file['upload_key'], bucket)\n",
    "        if not head_info:\n",
    "            print a_file['@id'], a_file['status']\n",
    "            file_not_found += 1\n",
    "            continue\n",
    "        file_size = head_info['ContentLength']\n",
    "\n",
    "        patch_data = {'file_size': file_size}\n",
    "        try:\n",
    "            ff_utils.patch_metadata(patch_data, obj_id=a_file['uuid'] ,ff_env=env)\n",
    "            success += 1\n",
    "        except Exception as e:\n",
    "            print e\n",
    "            print\n",
    "            patch_problem += 1\n",
    "\n",
    "print file_not_found, 'files missing from s3'\n",
    "print patch_problem, 'files had patch problems'\n",
    "print deleted, 'deleted files skipped'\n",
    "print uploading, 'uploading files skipped'\n",
    "print success, 'total files patched'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
